import akshare as ak
import pandas as pd
from datetime import datetime, timedelta
import time
import os
from concurrent.futures import ThreadPoolExecutor, as_completed
import warnings
from typing import Callable, Dict, Any, List
import pandas_ta as ta
import numpy as np
import xlsxwriter

# 忽略 pandas 的 SettingWithCopyWarning
warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)


# ==============================================================================
# 核心工具函数和配置
# ==============================================================================
class Config:
    """程序配置类"""

    def __init__(self):
        # 使用 os.path.expanduser('~') 确保跨平台兼容性
        self.HOME_DIRECTORY = os.path.expanduser('~')
        self.SAVE_DIRECTORY = os.path.join(self.HOME_DIRECTORY, 'Downloads', 'CoreNews_Reports')
        self.TEMP_DATA_DIRECTORY = os.path.join(self.SAVE_DIRECTORY, 'ShareData')
        
        self.DATA_FETCH_RETRIES = 3 # [cite: 2]
        self.DATA_FETCH_DELAY = 5  # [cite: 2]
        self.MAX_WORKERS = 15 # [cite: 2]
        self.CODE_ALIASES = {'代码': '股票代码', '证券代码': '股票代码', '股票代码': '股票代码'} # [cite: 2]
        self.NAME_ALIASES = {'名称': '股票简称', '股票名称': '股票简称', '股票简称': '股票简称', '简称': '股票简称',
                             '简': '股票简称', '证券名称': '股票简称'} # [cite: 2]
        self.PRICE_ALIASES = {'最新价': '最新价', 
                              '现价': '最新价', '当前价格': '最新价', '今收盘': '最新价',
                              '收盘': '最新价', '收盘价': '最新价'} # [cite: 3]


def format_stock_code(code: str) -> str:
    """根据股票代码的开头数字，添加市场前缀。"""
    code_str = str(code).zfill(6)
    if code_str.startswith('6'):
        return 'sh' + code_str
    elif code_str.startswith(('0', '3')):
        return 'sz' + code_str
    elif code_str.startswith(('4', '8')):
        return 'bj' + code_str # [cite: 4]
    return code_str

# ==============================================================================
# 核心分析类 (集成 Fetching, Processing, Reporting)
# ==============================================================================
class StockAnalyzer:

    def __init__(self):
        self.config = Config() # [cite: 4]
        self.today_str = datetime.now().strftime("%Y%m%d") # [cite: 4]
        self.temp_dir = self.config.TEMP_DATA_DIRECTORY # [cite: 4]
        os.makedirs(self.temp_dir, exist_ok=True) # [cite: 4]
        self.executor = ThreadPoolExecutor(max_workers=self.config.MAX_WORKERS) # [cite: 4]
        self.start_time = time.time() # [cite: 4]

    def _get_file_path(self, base_name: str, cleaned: bool = False) -> str:
        """
        生成临时数据文件的完整路径。
        如果 cleaned=True, 则添加 "_经清洗" 后缀。
        """ # [cite: 5]
        suffix = "_经清洗" if cleaned else "" # [cite: 5]
        file_name = f"{base_name}{suffix}_{self.today_str}.txt" # [cite: 5]
        return os.path.join(self.temp_dir, file_name) # [cite: 5]

    def _load_data_from_cache(self, file_path: str) -> pd.DataFrame:
        """从缓存加载数据。""" # [cite: 6]
        if os.path.exists(file_path): # [cite: 6]
            try:
                # 使用 '|' 分隔符，并确保股票代码是字符串格式
                df = pd.read_csv(file_path, sep='|', encoding='utf-8', dtype={'股票代码': str}) # [cite: 6, 7]
                print(f"  - 发现缓存，加载: {os.path.basename(file_path)}") # [cite: 7]
                return df # [cite: 7]
            except Exception as e:
                print(f"[WARN] 加载缓存 {os.path.basename(file_path)} 失败: {e}，将重新获取。") # [cite: 7]
      
        return pd.DataFrame() # [cite: 8]

    def _save_data_to_cache(self, df: pd.DataFrame, file_path: str):
        """保存数据到缓存。""" # [cite: 8]
        try:
            df.to_csv(file_path, sep='|', index=False, encoding='utf-8') # [cite: 8]
        except Exception as e:
            print(f"[ERROR] 保存数据到缓存 {os.path.basename(file_path)} 失败: {e}") # [cite: 8]

    def _safe_ak_fetch(self, fetch_func: Callable, file_base_name: str, **kwargs: Any) -> pd.DataFrame:

        # 1. 尝试从【清洗后的缓存】加载数据
       
        cleaned_file_path = self._get_file_path(file_base_name, cleaned=True) # [cite: 9]
        cached_df = self._load_data_from_cache(cleaned_file_path) # [cite: 9]
        if not cached_df.empty: # [cite: 9]
            return cached_df # [cite: 9]

        # 2. 如果清洗后的缓存不存在，则尝试从原始获取
        df = pd.DataFrame() # [cite: 9]
        for i in range(self.config.DATA_FETCH_RETRIES): # [cite: 10]
            try:
                print(f"  - 正在尝试第 {i + 1}/{self.config.DATA_FETCH_RETRIES} 次获取数据: {file_base_name}...") # [cite: 10]
                df = fetch_func(**kwargs) # [cite: 10]
                if df is not None and not df.empty: # [cite: 10]
                    break  # 成功获取数据，跳出重试循环
                else:
                
                    print(f"[WARN] 数据返回为空或无效: {file_base_name}，重试中.") # [cite: 11]
                    time.sleep(self.config.DATA_FETCH_DELAY) # [cite: 11]
            except Exception as e:
                print(f"[ERROR] 获取 {file_base_name} 时出错: {e}，将在 {self.config.DATA_FETCH_DELAY} 秒后重试。") # [cite: 11]
                time.sleep(self.config.DATA_FETCH_DELAY) # [cite: 11]

        if df.empty:
            
            print(f"[FATAL] 所有重试均失败，返回空 DataFrame: {file_base_name}") # [cite: 12]
            return pd.DataFrame() # [cite: 12]

        # 3. 清洗数据并保存到带有 "_经清洗" 后缀的缓存文件
        cleaned_df = self._clean_and_standardize(df, file_base_name) # [cite: 12]
        if not cleaned_df.empty: # [cite: 12]
            self._save_data_to_cache(cleaned_df, cleaned_file_path) # [cite: 12]

        return cleaned_df # [cite: 12]

    def _clean_and_standardize(self, df: pd.DataFrame, df_name: str) -> pd.DataFrame:
        """通用数据清洗和列名标准化。"""
        if df.empty: return df # [cite: 13]

        # 1. 标准化列名：使用 Config 中的别名映射
        for old, new in self.config.CODE_ALIASES.items(): # [cite: 13]
            if old in df.columns: df.rename(columns={old: new}, inplace=True) # [cite: 13]
        for old, new in self.config.NAME_ALIASES.items(): # [cite: 13]
            if old in df.columns: df.rename(columns={old: new}, inplace=True) # [cite: 13]
        for old, new in self.config.PRICE_ALIASES.items(): # [cite: 13]
            if old in df.columns: df.rename(columns={old: new}, inplace=True) # [cite: 14]

        if '股票代码' not in df.columns: # [cite: 14]
            return pd.DataFrame() # [cite: 14]

        # 2. 清洗数据
        df.dropna(subset=['股票代码'], inplace=True) # [cite: 14]
        df.drop_duplicates(subset=['股票代码'], inplace=True) # [cite: 14]
        df['股票代码'] = df['股票代码'].astype(str).str.zfill(6) # [cite: 14]

        if '最新价' in df.columns: # [cite: 14]
            # 使用 errors='coerce' 将任何非数字值强制转换为 NaN，确保列类型为 float
      
            df['最新价'] = pd.to_numeric(df['最新价'], errors='coerce') # [cite: 15]

        # 3. 过滤ST股 (依赖 '股票简称' 列)
        if '股票简称' not in df.columns: # [cite: 15]
            # 如果没有简称，就无法过滤 ST 股，但仍返回清洗过代码格式的 DF
            cleaned_df = df.copy() # [cite: 16]
        else:
            cleaned_df = df[~df['股票简称'].str.contains('ST|st|退市|bj|BJ', case=False, na=False)].copy() # [cite: 16]

        if len(cleaned_df) == 0:
 
            print(f"[WARN] {df_name} 数据清洗后为空。") # [cite: 16]
            return pd.DataFrame() # [cite: 16]

        return cleaned_df # [cite: 16]

    def _get_all_raw_data(self) -> Dict[str, pd.DataFrame]:
        """集中获取所有数据源。""" # [cite: 16]
        print("\n>>> 正在初始化数据获取和缓存检查...") # [cite: 16]

        # 1. 基础行情和研报数据
        data = {
            'spot_data_all': self._safe_ak_fetch(ak.stock_zh_a_spot, "A股实时行情"), # [cite: 17]
      
            'main_report_raw': self._safe_ak_fetch(ak.stock_profit_forecast_em, "主力研报盈利预测"), # [cite: 17]
            'financial_abstract_raw': self._safe_ak_fetch(ak.stock_financial_abstract, "财务摘要数据"), # [cite: 17]
            # 注意：ak.stock_fund_flow_individual 返回的列名在不同版本或获取模式下可能不同
            'market_fund_flow_raw': self._safe_ak_fetch(ak.stock_fund_flow_individual, "5日市场资金流向",
                                                  
                                                    symbol="5日排行"), # [cite: 18]
            'market_fund_flow_raw_10': self._safe_ak_fetch(ak.stock_fund_flow_individual, "10日市场资金流向",
                                                           symbol="10日排行"), # [cite: 18]
            'market_fund_flow_raw_20': self._safe_ak_fetch(ak.stock_fund_flow_individual, "20日市场资金流向",
       
                                                             symbol="20日排行"), # [cite: 19]
            'strong_stocks_raw': self._safe_ak_fetch(ak.stock_zt_pool_strong_em, "强势股池",
                                  
                                                     date=datetime.now().strftime('%Y%m%d')), # [cite: 20]
            'consecutive_rise_raw': self._safe_ak_fetch(ak.stock_rank_lxsz_ths, "连续上涨"), # [cite: 20]
            'ljqs_raw': self._safe_ak_fetch(ak.stock_rank_ljqs_ths, "量价齐升"), # [cite: 20]
            'cxfl_raw': self._safe_ak_fetch(ak.stock_rank_cxfl_ths, "持续放量"), # [cite: 20]
        }

        # 2. 均线突破数据 (Akshare接口参数不同，需分开获取)
        data['xstp_10_raw'] = self._safe_ak_fetch(ak.stock_rank_xstp_ths, "向上突破10日均线", symbol="10日均线") # [cite: 20]
        
        data['xstp_30_raw'] = self._safe_ak_fetch(ak.stock_rank_xstp_ths, "向上突破30日均线", symbol="30日均线") # [cite: 21]
        data['xstp_60_raw'] = self._safe_ak_fetch(ak.stock_rank_xstp_ths, "向上突破60日均线", symbol="60日均线") # 修正 symbol # [cite: 21]

        # 3. 行业板块数据
        print("\n>>> 正在获取行业板块成分股...") # [cite: 21]
        industry_board_df = self._safe_ak_fetch(ak.stock_board_industry_name_em, '行业板块名称') # [cite: 21]
        data['top_industry_cons_df'] = self._get_top_industry_constituents(industry_board_df) # [cite: 21]
        data['industry_board_df'] = industry_board_df  # 原始板块名称用于报告 # [cite: 21]

        return data # [cite: 21]

    def _safe_fetch_constituents(self, symbol: str) -> pd.DataFrame:
        """
  
        带重试机制获取单个行业板块的成分股。
        """ # [cite: 22]
        df = pd.DataFrame() # [cite: 22]
        for i in range(self.config.DATA_FETCH_RETRIES): # [cite: 22]
            try:
                df = ak.stock_board_industry_cons_em(symbol=symbol) # [cite: 22]
                if df is not None and not df.empty:
            
                    return df # [cite: 23]
                else:
                    time.sleep(self.config.DATA_FETCH_DELAY) # [cite: 23]
            except Exception:
                time.sleep(self.config.DATA_FETCH_DELAY) # [cite: 23]
        return pd.DataFrame() # [cite: 23]

    def _get_top_industry_constituents(self, industry_board_df: pd.DataFrame) -> pd.DataFrame:
        
        """获取涨幅前10板块的成分股。""" # [cite: 24]
        if industry_board_df.empty or '板块名称' not in industry_board_df.columns: # [cite: 24]
            return pd.DataFrame() # [cite: 24]

        cache_name = "TopIndustryConstituents_经清洗" # [cite: 24]
        cleaned_file_path = self._get_file_path(cache_name, cleaned=True) # [cite: 24]
        cached_df = self._load_data_from_cache(cleaned_file_path) # [cite: 24]
        if not cached_df.empty: # [cite: 24]
            return cached_df # [cite: 24]

        top_industries = industry_board_df.sort_values(by='涨跌幅', ascending=False).head(10) # [cite: 25]
        
        all_constituents = [] # [cite: 25]

        # 使用 ThreadPoolExecutor 并行获取成分股
        future_to_industry = {
            self.executor.submit(
                self._safe_fetch_constituents,
                symbol=row['板块名称']
            ): row['板块名称']
            for _, row in top_industries.iterrows()
    
        } # [cite: 26]

        for future in as_completed(future_to_industry): # [cite: 26]
            industry_name = future_to_industry[future] # [cite: 26]
            try:
                constituents_df = future.result() # [cite: 27]
                if constituents_df is not None and not constituents_df.empty:
                  
                    if '代码' in constituents_df.columns: # [cite: 27]
                        constituents_df.rename(columns={'代码': '股票代码'}, inplace=True) # [cite: 27]

                    if '股票代码' in constituents_df.columns: # [cite: 27]
                        constituents_df['股票代码'] = constituents_df['股票代码'].astype(str).zfill(6) # [cite: 28]
                    
                    constituents_df['所属板块'] = industry_name # [cite: 28]

                    cleaned_constituents = constituents_df[['股票代码', '所属板块']].drop_duplicates() # [cite: 28]
                    all_constituents.append(cleaned_constituents) # [cite: 28]
                else:
                    print(
               
                        f"[WARN] 警告：获取 {industry_name} 的成分股失败或数据为空 (已重试 {self.config.DATA_FETCH_RETRIES} 次).") # [cite: 29]

            except Exception as e:
                print(f"[ERROR] 错误：获取 {industry_name} 的成分股时发生未知错误: {e}") # [cite: 29]

        if all_constituents: # [cite: 29]
            final_df = pd.concat(all_constituents, ignore_index=True).drop_duplicates(subset=['股票代码']) # [cite: 30]
            self._save_data_to_cache(final_df, cleaned_file_path) # [cite: 30]
            return final_df # [cite: 30]
        return pd.DataFrame() # [cite: 30]

    def _fetch_hist_data_parallel(self, codes: List[str], days: int) -> pd.DataFrame:
        """
        并行获取指定股票的历史数据，并强制将 OHLCV 列名统一为英文小写。
        """ # [cite: 30]
        print(f"\n正在为 {len(codes)} 只股票下载 {days} 天的历史数据...") # [cite: 31]

        end_date = datetime.now() # [cite: 31]
        start_date = end_date - timedelta(days=days) # [cite: 31]
        start_date_str = start_date.strftime("%Y%m%d") # [cite: 31]
        end_date_str = end_date.strftime("%Y%m%d") # [cite: 31]

        cache_name = f"MACD_hist_data_cache_{len(codes)}" # [cite: 31]
        file_path = self._get_file_path(cache_name, cleaned=True) # [cite: 32]
        cached_df = self._load_data_from_cache(file_path) # [cite: 32]

        if not cached_df.empty: # [cite: 32]
            if 'date' in cached_df.columns: # [cite: 32]
                cached_df['date'] = pd.to_datetime(cached_df['date']).dt.strftime('%Y-%m-%d') # [cite: 32]
            if 'close' in cached_df.columns and 'open' in cached_df.columns: # [cite: 32]
       
                return cached_df # [cite: 32]
            else:
                print("[WARN] 历史数据缓存文件缺少关键英文列，将重新获取。") # [cite: 32]

        all_data = [] # [cite: 32]
        future_to_code = {} # [cite: 33]
        with ThreadPoolExecutor(max_workers=self.config.MAX_WORKERS) as executor: # [cite: 33]
            for code in codes:
               
                future = executor.submit( # [cite: 33]
                    ak.stock_zh_a_hist_tx,
                    symbol=format_stock_code(code),
                    start_date=start_date_str,
                    end_date=end_date_str,
                 
                    adjust="hfq"  # 前复权 # [cite: 34]
                )
                future_to_code[future] = code # [cite: 34]

        for future in as_completed(future_to_code): # [cite: 34]
            code = future_to_code[future] # [cite: 35]
            try:
                hist_df = future.result() # [cite: 35]
     
                if hist_df is not None and not hist_df.empty: # [cite: 35]

                    # 核心修复点：强制统一列名为英文小写
                    hist_df.rename(columns={
                        'date': 'date', '日期': 'date', # [cite: 36]
              
                        'open': 'open', '开盘': 'open', # [cite: 36]
                        'close': 'close', '收盘': 'close', # [cite: 36]
                        'high': 'high', '最高': 'high', # [cite: 37]
                        'low': 'low', '最低': 'low', # [cite: 37]
      
                        'volume': 'volume', '成交量': 'volume', 'amount': 'volume',  # 假设 amount 是成交量 # [cite: 37]
                    }, inplace=True, errors='ignore')

                    hist_df['股票代码'] = code # [cite: 37]

                    if 'date' in hist_df.columns: # [cite: 38]
     
                        hist_df['date'] = pd.to_datetime(hist_df['date']).dt.strftime('%Y-%m-%d') # [cite: 38]

                    cols_to_keep = ['date', 'open', 'close', 'high', 'low', 'volume', '股票代码'] # [cite: 38]
                    hist_df = hist_df[[col for col in cols_to_keep if col in hist_df.columns]] # [cite: 38]

                    all_data.append(hist_df) # [cite: 39]

 
            except Exception: # [cite: 39]
                # 简单捕获异常，不打印太多日志
                pass

        if all_data: # [cite: 39]
            merged_df = pd.concat(all_data, ignore_index=True) # [cite: 40]
            self._save_data_to_cache(merged_df, file_path) # [cite: 40]
            return merged_df # [cite: 40]
     
        return pd.DataFrame() # [cite: 40]

    # ==========================================================================
    # MACD 计算方法
    # ==========================================================================
    def _custom_macd(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        [自定义实现] 同时计算 MACD 标准周期 (12, 26, 9) 和加速周期 (6, 13, 5) 的快慢线金叉信号。
        **改进：区分零轴上金叉和零轴下金叉。**
        """ # [cite: 40]
        if 'close' not in df.columns: # [cite: 41]
            return df # [cite: 41]

   
        close = df['close'] # [cite: 41]

        macd_periods = {
            '12269': (12, 26, 9),  # 标准中长线周期 # [cite: 41]
            '6135': (6, 13, 5)  # 短线/加速周期 # [cite: 42]
        }

        for name, (fast, slow, signal) in macd_periods.items(): # [cite: 42]
            # 1. 计算 DIF
          
            df[f'DIF_{name}'] = close.ewm(span=fast, adjust=False).mean() - close.ewm(span=slow, adjust=False).mean() # [cite: 42]

            # 2. 计算 DEA
            df[f'DEA_{name}'] = df[f'DIF_{name}'].ewm(span=signal, adjust=False).mean() # [cite: 42]

            # 3. 判断 MACD 金叉信号 (DIF 上穿 DEA) 和零轴位置
            dif_col = f'DIF_{name}' # [cite: 43]
            dea_col = f'DEA_{name}' # [cite: 43]
            signal_col = f'MACD_{name}_SIGNAL_DETAIL' # [cite: 43]

            # 判定金叉的布尔序列
            is_cross = (df[dif_col] > df[dea_col]) & \
                     (df[dif_col].shift(1).fillna(0) <= df[dea_col].shift(1).fillna(0)) # [cite: 43]

            # 核心修改：区分零轴上/下金叉
            df[signal_col] = np.where( # [cite: 44]
                is_cross,
   
                np.where( # [cite: 44]
                    # 零轴上金叉条件: 金叉发生，且 DIF 和 DEA 均大于 0
                    (df[dif_col] > 0) & (df[dea_col] > 0),
                    '零轴上金叉', # [cite: 45]
              
                    # 零轴下金叉条件: 金叉发生
                    '零轴下金叉' # [cite: 45]
                ),
                ''  # 非金叉，返回空字符串
            )

        return df # [cite: 46]

    # ==========================================================================
    # MACD 动能状态计算辅助函数
    # 
    # ==========================================================================
    def _calculate_macd_momentum(self, df: pd.DataFrame, dif_col: str, dea_col: str) -> str:
        """
        计算 MACD 动能状态: 加速上涨/减速上涨/加速下跌/减速下跌
        """ # [cite: 46]
        if len(df) < 2: # [cite: 46]
            return "N/A (数据不足)" # [cite: 46]

        # 获取最新的 DIF, DEA 值和前一天的 DIF 值
        latest_dif = df[dif_col].iloc[-1] # [cite: 47]
        latest_dea = df[dea_col].iloc[-1] # [cite: 47]
 
        prev_dif = df[dif_col].iloc[-2] # [cite: 47]
        
        # DIF 线的变化 (MACD 柱的变化方向)
        dif_change = latest_dif - prev_dif # [cite: 47]
        
        momentum_state = "" # [cite: 47]
        
        if latest_dif >= latest_dea: # [cite: 48]
            # DIF 在 DEA 之上 (多头区域/红柱)
     
            if dif_change > 0: # [cite: 48]
                momentum_state = "加速上涨 (红柱加长)" # [cite: 48]
            elif dif_change <= 0: # [cite: 48]
                momentum_state = "减速上涨 (红柱缩短)" # [cite: 48]
        else:
            # DIF 在 DEA 之下 (空头区域/绿柱)
            
            if dif_change < 0: # [cite: 49]
                momentum_state = "加速下跌 (绿柱加长)" # [cite: 49]
            elif dif_change >= 0: # [cite: 49]
                momentum_state = "减速下跌 (绿柱缩短)" # [cite: 49]
                
        return momentum_state # [cite: 49]

    # ==========================================================================
    # CCI 专业化分类函数
    # ==========================================================================
   
    def _classify_cci_level(self, cci_value: float) -> str:
        """根据CCI值，将其分类为专业的市场状态术语。""" # [cite: 50]
        if pd.isna(cci_value): # [cite: 50]
            return 'N/A' # [cite: 50]

        if cci_value > 200: # [cite: 50]
            return f'极度超买 ({cci_value:.2f})' # [cite: 50]
        elif cci_value >= 100: # [cite: 50]
            return f'强势超买 ({cci_value:.2f})' # [cite: 51]
        elif cci_value > -100: # [cite: 51]
   
            return '' # 常态波动不记录 # [cite: 51]
        elif cci_value >= -200: # [cite: 51]
            return f'弱势超卖 ({cci_value:.2f})' # [cite: 51]
        else:
            return f'极度超卖 ({cci_value:.2f})' # [cite: 51]


    def _save_ta_signals_to_txt(self, ta_signals: Dict[str, pd.DataFrame]):
        """
        将技术指标信号结果保存到独立的 TXT 文件。
        """
       
        print("\n>>> 正在保存技术指标信号到本地 TXT 文件...") # [cite: 52]

        save_dir = self.config.TEMP_DATA_DIRECTORY # [cite: 52]
        today_str = self.today_str # [cite: 52]

        for indicator_name, df in ta_signals.items(): # [cite: 52]
            if df is None or df.empty: # [cite: 52]
                continue # [cite: 52]

            file_name = f"{indicator_name}_Signals_{today_str}.txt" # [cite: 52]
            file_path = os.path.join(save_dir, file_name) # [cite: 53]

  
            try:
                df.to_csv(file_path, sep='|', index=False, encoding='utf-8') # [cite: 53]
                print(f"  - 成功保存 {indicator_name} 信号文件: {file_name}") # [cite: 53]
            except Exception as e:
                print(f"[ERROR] 保存 {indicator_name} 信号文件失败: {e}") # [cite: 53]

    # ==========================================================================
    # _process_ta_signals: 提取详细 MACD 信号并计算动能状态
 
    # ==========================================================================
    def _process_ta_signals(self, all_codes: List[str], hist_df_all: pd.DataFrame, spot_df: pd.DataFrame) -> Dict[
        str, pd.DataFrame]:
        """计算并提取所有技术指标信号。""" # [cite: 54]
        print(f"\n正在对 {len(all_codes)} 只股票进行技术分析...") # [cite: 54]

        ta_signals = {'MACD_12269': [], 'MACD_6135': [], 'KDJ': [], 'CCI': [], 'RSI': [], 'BOLL': [], 
                      'MACD_DIF_MOMENTUM': []} # [cite: 54]

        if hist_df_all.empty:
 
            print("[WARN] 历史数据为空，跳过技术分析。") # [cite: 55]
            return {key: pd.DataFrame(columns=['股票代码', f'{key}_Signal']) for key in ta_signals.keys()} # [cite: 55]

        hist_df_all.sort_values(['股票代码', 'date'], inplace=True) # [cite: 55]

        for code in all_codes: # [cite: 55]
            df = hist_df_all[hist_df_all['股票代码'] == code].copy() # [cite: 56]

            if df.empty or len(df) < 30: # [cite: 56]
               
                continue # [cite: 56]

            for col in ['close', 'open', 'high', 'low']: # [cite: 56]
                if col in df.columns: # [cite: 56]
                    df[col] = pd.to_numeric(df[col], errors='coerce') # [cite: 57]

            df.dropna(subset=['close'], inplace=True) # [cite: 57]
            if df.empty: continue # [cite: 57]

            
            if 'close' not in df.columns or 'open' not in df.columns or 'high' not in df.columns or 'low' not in df.columns: # [cite: 57]
                print(f"[ERROR] 股票 {code}: 历史数据中缺少必要的 OHLC 列，跳过 TA 计算。") # [cite: 58]
                continue # [cite: 58]

            try:
                # 1. MACD (金叉) - 计算并提取两种周期的信号
         
                df = self._custom_macd(df) # [cite: 58]
                
                # --- MACD Momentum and DIF/DEA extraction START ---
                dif_12269_col = 'DIF_12269' # [cite: 58]
                dea_12269_col = 'DEA_12269' # [cite: 59]
               
                dif_6135_col = 'DIF_6135' # [cite: 59]
                dea_6135_col = 'DEA_6135' # [cite: 59]
                
                latest_row = df.iloc[-1] # [cite: 59]
                
                momentum_12269 = self._calculate_macd_momentum(df, dif_12269_col, dea_12269_col) # [cite: 60]
         
                momentum_6135 = self._calculate_macd_momentum(df, dif_6135_col, dea_6135_col) # [cite: 60]
                
                ta_signals['MACD_DIF_MOMENTUM'].append({
                    '股票代码': code,
                    'MACD_12269_DIF': latest_row[dif_12269_col], # [cite: 61]
              
                    'MACD_12269_动能': momentum_12269, # [cite: 61]
                    'MACD_6135_DIF': latest_row[dif_6135_col], # [cite: 61]
                    'MACD_6135_动能': momentum_6135, # [cite: 61]
                })

                detail_col_12269 = 'MACD_12269_SIGNAL_DETAIL' # [cite: 62]
                if detail_col_12269 in df.columns: # [cite: 62]
                    signal_detail = df[detail_col_12269].iloc[-1] # [cite: 62]
                    if signal_detail != '': # [cite: 62]
                        ta_signals['MACD_12269'].append({'股票代码': code, 'MACD_12269_Signal': signal_detail}) # [cite: 62]

                detail_col_6135 = 'MACD_6135_SIGNAL_DETAIL' # [cite: 63]
        
                if detail_col_6135 in df.columns: # [cite: 63]
                    signal_detail = df[detail_col_6135].iloc[-1] # [cite: 63]
                    if signal_detail != '': # [cite: 63]
                        ta_signals['MACD_6135'].append({'股票代码': code, 'MACD_6135_Signal': signal_detail}) # [cite: 63]
                # 
                # --- MACD 自定义计算结束 --- # [cite: 64]


                # 2. KDJ 信号
                df.ta.stoch(append=True, close='close', high='high', low='low') # [cite: 64]
                kdj_cols = [col for col in df.columns if col.startswith('STOCHk_') or col.startswith('STOCHd_')] # [cite: 65]

                if len(kdj_cols) >= 2: # [cite: 65]
              
                    k_col = kdj_cols[0] # [cite: 65]
                    d_col = kdj_cols[1] # [cite: 65]
                    j_col = 'KDJ_J' # [cite: 65]

                    df[j_col] = 3 * df[k_col] - 2 * df[d_col] # [cite: 66]

                    
                    kdj_cross = (df[k_col] > df[d_col]) & (df[k_col].shift(1) <= df[d_col].shift(1)) # [cite: 66]
                    
                    window = 10 # [cite: 66]
                    curr_low = df['low'].iloc[-1] # [cite: 67]
                    min_low_window = df['low'].iloc[-window:-1].min() # [cite: 67]
      
                    curr_k = df[k_col].iloc[-1] # [cite: 67]
                    min_k_window = df[k_col].iloc[-window:-1].min() # [cite: 67]

                    is_divergence = (curr_low <= min_low_window * 1.02) & (curr_k > min_k_window * 1.1) # [cite: 68]

                    ma5 = df['close'].rolling(window=5).mean() # [cite: 68]
        
                    above_ma5 = df['close'] > ma5 # [cite: 68]

                    current_idx = df.index[-1] # [cite: 68]
                    last_row = df.iloc[-1] # [cite: 69]
                    prev_row = df.iloc[-2] # [cite: 69]

                  
                    signal_msg = "" # [cite: 69]
                    kd_oversold = (df[k_col] < 20) & (df[d_col] < 20) # [cite: 69]

                    if prev_row[j_col] < 0 and last_row[j_col] > 5 and kdj_cross.iloc[-1]: # [cite: 70]
                        signal_msg = "极值J线反转" # [cite: 70]
             
                    elif kdj_cross.iloc[-1] and is_divergence and last_row[k_col] < 30: # [cite: 70]
                        signal_msg = "底背离金叉" # [cite: 70]
                    elif (kd_oversold.iloc[-5:-1].sum() > 0) and kdj_cross.iloc[-1] and above_ma5.iloc[-1]: # [cite: 71]
                        signal_msg = "趋势确认金叉" # [cite: 71]
       
                    elif (kd_oversold.iloc[-5:-1].sum() > 0) and kdj_cross.iloc[-1]: # [cite: 71]
                        signal_msg = "低位超卖金叉" # [cite: 71]

                    if signal_msg: # [cite: 71]
                        ta_signals['KDJ'].append({
           
                            '股票代码': code, # [cite: 72]
                            'KDJ_Signal': f"{signal_msg} (K={last_row[k_col]:.1f}, J={last_row[j_col]:.1f})" # [cite: 72]
                        })

                # 3. CCI (专业分类)
        
                df.ta.cci(append=True, close='close', high='high', low='low') # [cite: 73]
                cci_cols = [col for col in df.columns if col.startswith('CCI_')] # [cite: 73]
                if cci_cols: # [cite: 73]
                    cci_col = cci_cols[0] # [cite: 74]
                    current_cci = df[cci_col].iloc[-1] # [cite: 74]
    
                    cci_signal = self._classify_cci_level(current_cci) # [cite: 74]

                    if cci_signal: # [cite: 74]
                        ta_signals['CCI'].append(
                            {'股票代码': code, 'CCI_Signal': cci_signal}) # [cite: 75]

      
                # 4. RSI (超卖低位)
                df.ta.rsi(append=True, close='close') # [cite: 75]
                rsi_cols = [col for col in df.columns if col.startswith('RSI_')] # [cite: 75]
                if rsi_cols: # [cite: 76]
                    rsi_col = rsi_cols[0] # [cite: 76]
       
                    if df[rsi_col].iloc[-1] < 30: # [cite: 76]
                        ta_signals['RSI'].append(
                            {'股票代码': code, 'RSI_Signal': f"超卖低位 ({df[rsi_col].iloc[-1]:.2f})"}) # [cite: 76]

                # 5. BOLL (低波/缩口)
         
                df.ta.bbands(append=True, length=20, std=2, close='close') # [cite: 77]
                boll_cols = [col for col in df.columns if col.startswith('BBL_')] # [cite: 77]
                if boll_cols: # [cite: 77]
                    lower_band = boll_cols[0] # [cite: 77]
                    upper_band = [col for col in df.columns # [cite: 78]
                                  if col.startswith('BBU_')][0]
                    df['BOLL_BANDWIDTH'] = (df[upper_band] - df[lower_band]) / df['close'] # [cite: 78]
                    if df['BOLL_BANDWIDTH'].iloc[-5:].mean() < df['BOLL_BANDWIDTH'].mean(): # [cite: 78]
                        ta_signals['BOLL'].append({'股票代码': code, 'BOLL_Signal': '低波/缩口'}) # [cite: 79]

            except KeyError as ke:
        
                print(f"[ERROR] 计算 {code} 的 TA 指标时出错: 关键指标列名丢失 ({ke})") # [cite: 79]
            except Exception as e:
                print(f"[ERROR] 计算 {code} 的 TA 指标时出错: {e}") # [cite: 79]
                continue # [cite: 79]

        final_ta_dfs = {} # [cite: 80]
        for key, value in ta_signals.items(): # [cite: 80]
          
            final_ta_dfs[key] = pd.DataFrame(value) # [cite: 80]

        return final_ta_dfs # [cite: 80]

    def _process_xstp_and_filter(self, raw_data: Dict[str, pd.DataFrame], spot_df: pd.DataFrame) -> pd.DataFrame:
        """处理并合并均线突破数据，并进行多头排列筛选。""" # [cite: 80]
        print("正在处理并合并均线突破数据...") # [cite: 81]

        processed_df10 = raw_data['xstp_10_raw'].rename(columns={'最新价': '10日均线最新价'}) # [cite: 81]
        processed_df30 = raw_data['xstp_30_raw'].rename(columns={'最新价': '30日均线最新价'}) # [cite: 81]
        processed_df60 = raw_data['xstp_60_raw'].rename(columns={'最新价': '60日均线最新价'}) # [cite: 81]

        merged_df = pd.concat([
            processed_df10[['股票代码', '股票简称']].dropna(subset=['股票代码']),
   
            processed_df30[['股票代码', '股票简称']].dropna(subset=['股票代码']), # [cite: 81]
            processed_df60[['股票代码', '股票简称']].dropna(subset=['股票代码']) # [cite: 82]
        ]).drop_duplicates(subset=['股票代码']) # [cite: 82]

        xstp_base = merged_df[['股票代码', '股票简称']].drop_duplicates() # [cite: 82]
        xstp_base = pd.merge(xstp_base, processed_df10[['股票代码', '10日均线最新价']], on='股票代码', how='left') # [cite: 82]
        xstp_base = pd.merge(xstp_base, processed_df30[['股票代码', '30日均线最新价']], on='股票代码', how='left') # [cite: 82]
        xstp_base = pd.merge(xstp_base, processed_df60[['股票代码', '60日均线最新价']], on='股票代码', how='left') # [cite: 82]

        xstp_base = pd.merge(xstp_base, spot_df[['股票代码', '最新价']], on='股票代码', how='left') # [cite: 82]

  
        cols_to_convert = [col for col in xstp_base.columns if '最新价' in col or col == '最新价'] # [cite: 82]
        for col in cols_to_convert: # [cite: 82]
            xstp_base[col] = pd.to_numeric(xstp_base[col], errors='coerce') # [cite: 83]

        filtered_df = xstp_base[
            (xstp_base['最新价'] > xstp_base['10日均线最新价']) & (
                (xstp_base['10日均线最新价'] > xstp_base['30日均线最新价'].fillna(float('-inf'))) | # [cite: 83]
                (
                    xstp_base['30日均线最新价'] > xstp_base['60日均线最新价'].fillna(float('-inf'))) # [cite: 83]
            )
        ].copy() # [cite: 84]

        filtered_df['完全多头排列'] = filtered_df.apply(
            lambda row: '是' if row['10日均线最新价'] > row['30日均线最新价'] and row['30日均线最新价'] > row[
                '60日均线最新价'] else '否', axis=1
       
        ) # [cite: 84]

        filtered_df.rename(columns={'最新价': '当前价格'}, inplace=True) # [cite: 84]
        return filtered_df.fillna('N/A') # [cite: 84]

    # ==========================================================================
    # _consolidate_data: 修正汇总报告范围和去重逻辑 (解决了用户提出的两个问题)
    # ==========================================================================
    def _consolidate_data(self, processed_data: Dict[str, pd.DataFrame]) -> pd.DataFrame:
        """合并所有数据源和信号，生成最终汇总报告。"""
        print("\n>>> 正在汇总所有数据和信号 (技术指标作为独立列)...")

        # 1. 修正：基础股票代码应【仅】来源于已筛选的主力研报数据 (解决问题一)
        main_report_df = processed_data.get('processed_main_report', pd.DataFrame()) # [cite: 85]

        if main_report_df.empty or '股票代码' not in main_report_df.columns:
            print("[WARN] 主力研报清洗后的数据为空或缺少'股票代码'列，无法生成汇总报告。")
            return pd.DataFrame()

        # 仅以研报满足条件的股票代码为基础，并确保去重
        all_codes = main_report_df['股票代码'].unique()
        final_df = pd.DataFrame(list(all_codes), columns=['股票代码']) # [cite: 87]
        final_df['股票代码'] = final_df['股票代码'].astype(str) # [cite: 87]

        # 2. 鲁棒地合并基础信息 (简称, 价格) (解决问题二 - 确保去重)
        spot_df = processed_data.get('spot_data_all', pd.DataFrame()) # [cite: 88]
        report_df_base = processed_data.get('processed_main_report', pd.DataFrame()) # [cite: 88]

        if '股票代码' in spot_df.columns: # [cite: 88]
            spot_df['股票代码'] = spot_df['股票代码'].astype(str) # [cite: 88]
            
        # 确保用于合并的基础名称是彻底去重且仅包含所需列
        name_source_spot = spot_df[['股票代码', '股票简称']].drop_duplicates(
            subset=['股票代码']) if '股票简称' in spot_df.columns else pd.DataFrame() # [cite: 89]
     
        name_source_report = report_df_base[['股票代码', '股票简称']].drop_duplicates(
            subset=['股票代码']) if '股票简称' in report_df_base.columns else pd.DataFrame() # [cite: 89]
            
        all_names = pd.concat([name_source_spot, name_source_report]).drop_duplicates(subset=['股票代码'], keep='first') # [cite: 89]
        
        final_df = pd.merge(final_df, all_names, on='股票代码', how='left') # [cite: 89]

        if '股票简称' not in spot_df.columns: # [cite: 89]
            print("[FATAL] 实时行情数据中缺少 '股票简称' 列，无法按要求按简称关联。回退到按代码关联。") # [cite: 90]
    
            price_source_key = '股票代码' # [cite: 90]
            price_source = spot_df[['股票代码', '最新价']].copy() # [cite: 90]
        else:
            price_source_key = '股票简称' # [cite: 90]
            price_source = spot_df[['股票简称', '最新价']].copy() # [cite: 90]

        price_source['最新价'] = pd.to_numeric(price_source['最新价'], errors='coerce') # [cite: 91]
        price_source = price_source[
            (price_source['最新价'].notna()) & (price_source['最新价'] > 0)
 
        ].copy() # [cite: 91]
        # 核心去重：防止因简称/代码重复导致的价格关联问题 (解决问题二)
        price_source = price_source.drop_duplicates(subset=[price_source_key], keep='first') # [cite: 91]
        final_df.drop(columns=['最新价'], errors='ignore', inplace=True) # [cite: 91]

        if price_source_key in final_df.columns: # [cite: 91]
            final_df[price_source_key] = final_df[price_source_key].astype(str) # [cite: 92]
            price_source[price_source_key] = price_source[price_source_key].astype(str) # [cite: 92]
            final_df = pd.merge(final_df, price_source, on=price_source_key, how='left') # [cite: 92]

        valid_prices_count = final_df['最新价'].notna().sum() if '最新价' in final_df.columns else 0 # [cite: 92]
        print(
            f" - 实时行情数据 (最新价) 成功通过 '{price_source_key}' 关联的有效价格数量: {valid_prices_count} / {len(final_df)}") # [cite: 92]

        final_df['股票简称'] = final_df['股票简称'].fillna('N/A') # [cite: 93]

        # 3. 合并技术指标信号
        macd_12269_df = processed_data.get('MACD_12269', pd.DataFrame())[['股票代码', 'MACD_12269_Signal']] # [cite: 93]
        final_df = pd.merge(final_df, macd_12269_df, on='股票代码', how='left') # [cite: 93]
        macd_6135_df = processed_data.get('MACD_6135', pd.DataFrame())[['股票代码', 'MACD_6135_Signal']] # [cite: 93]
        final_df = pd.merge(final_df, macd_6135_df, on='股票代码', how='left') # [cite: 93]

 
        macd_dif_momentum_df = processed_data.get('MACD_DIF_MOMENTUM', pd.DataFrame()) # [cite: 93]
        if not macd_dif_momentum_df.empty: # [cite: 94]
            cols_to_merge = ['MACD_12269_DIF', 'MACD_12269_动能', 'MACD_6135_DIF', 'MACD_6135_动能'] # [cite: 94]
            # 确保列名在 DF 中存在 (避免 KeyError)
            valid_cols = [col for col in cols_to_merge if col in macd_dif_momentum_df.columns] # [cite: 94]
            final_df = pd.merge(final_df, macd_dif_momentum_df[['股票代码'] + valid_cols], 
      
                                on='股票代码', how='left') # [cite: 94]

        kdj_df = processed_data.get('KDJ', pd.DataFrame())[['股票代码', 'KDJ_Signal']] # [cite: 94]
        final_df = pd.merge(final_df, kdj_df, on='股票代码', how='left') # [cite: 95]

        cci_df = processed_data.get('CCI', pd.DataFrame())[['股票代码', 'CCI_Signal']] # [cite: 95]
        final_df = pd.merge(final_df, cci_df, on='股票代码', how='left') # [cite: 95]

        rsi_df = processed_data.get('RSI', pd.DataFrame())[['股票代码', 'RSI_Signal']] # [cite: 95]
        final_df = pd.merge(final_df, 
                            rsi_df, on='股票代码', how='left') # [cite: 95]

        boll_df = processed_data.get('BOLL', pd.DataFrame())[['股票代码', 'BOLL_Signal']] # [cite: 95]
        final_df = pd.merge(final_df, boll_df, on='股票代码', how='left') # [cite: 96]


        # 4. 合并研报数据 (已修复)
        report_df = processed_data.get('processed_main_report', pd.DataFrame()) # [cite: 96]
        if not report_df.empty: # [cite: 96]
            # 仅使用实际存在的 EPS 预测列和研报数量
            report_cols_available = ['股票代码', '研报数', '2024预测每股收益', '2025预测每股收益', 
        
                                     '2026预测每股收益', '2027预测每股收益', '最新研报日期'] # [cite: 96]
            
            report_cols_to_merge = [col for col in report_cols_available if col in report_df.columns] # [cite: 96]
            
            final_df = pd.merge(final_df, report_df[report_cols_to_merge], on='股票代码', how='left') # [cite: 97]
      
            if '研报数' in final_df.columns: # [cite: 97]
                final_df.rename(columns={'研报数': '研报数量'}, inplace=True) # [cite: 97]


        # 5. 合并资金流向数据 (已修复)
        def merge_fund_flow(df, days):
            if df.empty: 
                return pd.DataFrame()

         
            # 检查实际存在的列 '资金流入净额'
            if '资金流入净额' not in df.columns: # [cite: 98]
                # 打印警告并返回空 DataFrame，安全退出
                print(f"[WARN] 资金流向 {days} 日数据中缺少关键列 '资金流入净额'，跳过合并。") # [cite: 98]
                return pd.DataFrame() # [cite: 99]
            
            
            # 由于 '主力净额' 缺失，只处理 '资金流入净额'
            original_cols = ['资金流入净额'] # [cite: 99]
            new_cols = [f'{days}日主力净流入'] # 映射到程序中使用的 '主力净流入' # [cite: 99]
            
            # 构建列名映射字典
            rename_map = dict(zip(original_cols, new_cols)) # [cite: 100]
            
            # 
            # 重命名列
            df_renamed = df.rename(columns=rename_map) # [cite: 100]

            # 最终选择的列：股票代码 + 重命名后的列 (只选择一个资金列)
            cols_to_select = ['股票代码'] + new_cols # [cite: 100]
            
            # 返回结果
            return df_renamed[cols_to_select] # [cite: 101]

        fund_5 = merge_fund_flow(processed_data.get('market_fund_flow_raw', pd.DataFrame()), 5) # [cite: 101]
    
        fund_10 = merge_fund_flow(processed_data.get('market_fund_flow_raw_10', pd.DataFrame()), 10) # [cite: 101]
        fund_20 = merge_fund_flow(processed_data.get('market_fund_flow_raw_20', pd.DataFrame()), 20) # [cite: 102]

        final_df = pd.merge(final_df, fund_5, on='股票代码', how='left') # [cite: 102]
        final_df = pd.merge(final_df, fund_10, on='股票代码', how='left') # [cite: 102]
        final_df = pd.merge(final_df, fund_20, on='股票代码', how='left') # [cite: 102]


        # 6. 合并其他信号 (强势股，连涨，量价齐升，持续放量)
        def merge_simple_signal(df, signal_name):
            if df.empty: return pd.DataFrame() # [cite: 102]
     
            df[signal_name] = '是' # [cite: 102]
            return df[['股票代码', signal_name]] # [cite: 102]

        strong = merge_simple_signal(processed_data.get('strong_stocks_raw', pd.DataFrame()), '强势股池') # [cite: 103]
        consecutive = merge_simple_signal(processed_data.get('consecutive_rise_raw', pd.DataFrame()), '连续上涨') # [cite: 103]
        ljqs = merge_simple_signal(processed_data.get('ljqs_raw', pd.DataFrame()), '量价齐升') # [cite: 103]
        cxfl = merge_simple_signal(processed_data.get('cxfl_raw', pd.DataFrame()), '持续放量') # [cite: 103]

        final_df = pd.merge(final_df, strong, on='股票代码', how='left') # [cite: 103]
        final_df = pd.merge(final_df, consecutive, on='股票代码', how='left') # [cite: 103]
   
        final_df = pd.merge(final_df, ljqs, on='股票代码', how='left') # [cite: 103]
        final_df = pd.merge(final_df, cxfl, on='股票代码', how='left') # [cite: 104]

        return final_df.fillna('N/A') # [cite: 104]

    # ==========================================================================
    # generate_final_excel: 添加 MACD DIF 和动能状态表
    # ==========================================================================
    def generate_final_excel(self, ta_signals: Dict[str, pd.DataFrame], processed_data: Dict[str, pd.DataFrame],
                             raw_data: Dict[str, pd.DataFrame]):
       
        """生成最终的 Excel 报告文件。""" # [cite: 104]
        
        output_file = os.path.join(self.config.SAVE_DIRECTORY, f"A股精选分析报告_{self.today_str}.xlsx") # [cite: 104]
        print(f"\n>>> 正在生成 Excel 报告: {output_file}...") # [cite: 104]

        # 1. 汇总数据
        final_report_df = self._consolidate_data(processed_data) # [cite: 105]
        
        processed_xstp_df = processed_data.get('processed_xstp_df', pd.DataFrame()) # [cite: 105]
        spot_df = raw_data.get('spot_data_all', pd.DataFrame()) # [cite: 105]

        # 2. 定义所有需要写入工作表的数据字典
      
        all_sheets = {
            '汇总报告': final_report_df, # [cite: 105]
            '主力研报筛选': processed_data['processed_main_report'], # [cite: 105]
            '均线多头排列': processed_xstp_df, # [cite: 105]
            '实时行情': spot_df, # [cite: 105]
            '5日市场资金流向': raw_data['market_fund_flow_raw'], # [cite: 105]
            '10日市场资金流向': raw_data['market_fund_flow_raw_10'], # [cite: 106]
            '20日市场资金流向': raw_data['market_fund_flow_raw_20'], # [cite: 106]
     
            '强势股池': raw_data['strong_stocks_raw'], # [cite: 106]
            '连续上涨': raw_data['consecutive_rise_raw'], # [cite: 106]
            '量价齐升': raw_data['ljqs_raw'], # [cite: 106]
            '持续放量': raw_data['cxfl_raw'], # [cite: 106]
            'MACD_12269金叉': ta_signals.get('MACD_12269', pd.DataFrame()), # [cite: 107]
            'MACD_6135金叉': ta_signals.get('MACD_6135', pd.DataFrame()), # [cite: 107]
            'MACD_DIF_动能状态': ta_signals.get('MACD_DIF_MOMENTUM', pd.DataFrame()), # [cite: 107]
           
            'KDJ超卖金叉': ta_signals.get('KDJ', pd.DataFrame()), # [cite: 107]
            'CCI专业状态': ta_signals.get('CCI', pd.DataFrame()), # [cite: 107]
            'RSI超卖': ta_signals.get('RSI', pd.DataFrame()), # [cite: 107]
            'BOLL低波': ta_signals.get('BOLL', pd.DataFrame()), # [cite: 108]
            '前十板块成分股': processed_data['top_industry_cons_df'], # [cite: 108]
        }

        # 3. 写入 Excel 文件
        try:
            with pd.ExcelWriter(output_file, 
                                 engine='xlsxwriter') as writer: # [cite: 108]
                for sheet_name, df in all_sheets.items(): # [cite: 108]
                    if df is not None and not df.empty: # [cite: 109]
                        # 确保所有数字列在写入前转换为 float 或 int
                       
                        for col in df.columns: # [cite: 109]
                            if df[col].dtype == object and df[col].astype(str).str.contains('[^\d\.-]', na=False).sum() == 0: # [cite: 110]
                                try:
                            
                                    df[col] = pd.to_numeric(df[col], errors='coerce') # [cite: 110]
                                except:
                                    pass # [cite: 111]

                     
                        df.to_excel(writer, sheet_name=sheet_name, index=False) # [cite: 111]
                        
                        # 自动调整列宽
                        workbook = writer.book # [cite: 112]
                    
                        worksheet = writer.sheets[sheet_name] # [cite: 112]
                        
                        for i, col in enumerate(df.columns): # [cite: 112]
                            max_len = max(df[col].astype(str).str.len().max(), len(col)) + 2 # [cite: 113]
         
                            max_len = min(max_len, 40) # [cite: 113]
                            worksheet.set_column(i, i, max_len) # [cite: 113]


            print(f"\n✅ 报告生成成功. 文件已保存至: {output_file}") # [cite: 113]
            print(f"总耗时: {time.time() - self.start_time:.2f} 秒") # [cite: 114]

        except Exception as e:
       
            print(f"\n[FATAL] 写入 Excel 文件失败: {e}") # [cite: 114]


    # ==========================================================================
    # analyze_shares: 修正研报数据处理逻辑
    # ==========================================================================
    def analyze_shares(self):
        """主运行方法。""" # [cite: 114]
        # 1. 获取所有原始数据
        raw_data = self._get_all_raw_data() # [cite: 114]
        
        spot_df = raw_data.get('spot_data_all', pd.DataFrame()) # [cite: 115]

        # 2. 预处理研报数据，筛选出有预测 EPS 的
        processed_main_report = raw_data.get('main_report_raw', 
                                             pd.DataFrame()).copy() # [cite: 115]
        if not processed_main_report.empty: # [cite: 115]
            
            eps_col = '2024预测每股收益' # [cite: 115]
            
            if eps_col in processed_main_report.columns: # [cite: 116]
                processed_main_report[eps_col] = pd.to_numeric(processed_main_report[eps_col], errors='coerce') # [cite: 116]
            else:
     
                print("[WARN] 研报数据中缺少 '2024预测每股收益' 列，跳过研报清洗。") # [cite: 116]
                processed_main_report = pd.DataFrame() # [cite: 116]

            if '最新研报日期' in processed_main_report.columns: # [cite: 117]
                processed_main_report['最新研报日期'] = pd.to_datetime(processed_main_report['最新研报日期'], errors='coerce').dt.strftime('%Y-%m-%d') # [cite: 117]
            else:
                processed_main_report['最新研报日期'] = 'N/A' # [cite: 117] 
   
              
            # FIX: 过滤掉没有预测 EPS 的行
            if not processed_main_report.empty and eps_col in processed_main_report.columns: # [cite: 117]
                processed_main_report = processed_main_report[processed_main_report[eps_col].notna()].copy() # [cite: 118]
                processed_main_report = self._clean_and_standardize(processed_main_report, '主力研报(清洗后)') # [cite: 118]
                
                if '最新研报日期' in processed_main_report.columns and processed_main_report['最新研报日期'].astype(str).str.contains('\d{4}-\d{2}-\d{2}', regex=True).any(): # [cite: 118]
                     processed_main_report.sort_values(by='最新研报日期', ascending=False, inplace=True) # [cite: 119]
                
                processed_main_report.drop_duplicates(subset=['股票代码'], keep='first', inplace=True) # [cite: 119]
            else:
         
                processed_main_report = pd.DataFrame() # [cite: 119]

        
        # 3. 处理均线突破数据并进行多头排列筛选
        processed_xstp_df = self._process_xstp_and_filter(raw_data, spot_df) # [cite: 119]
        
        # 4. 准备进行技术分析的股票代码列表
        ta_codes = list(processed_xstp_df['股票代码'].unique()) # [cite: 120]
        if not ta_codes: # [cite: 120]
            ta_codes = list(spot_df['股票代码'].head(500).unique()) # [cite: 120]
        
 
        if not ta_codes: # [cite: 120]
            print("[WARN] 没有股票代码可用于技术分析。") # [cite: 120]
            return # [cite: 120]

        # 5. 获取历史数据
        hist_df_all = self._fetch_hist_data_parallel(ta_codes, days=100) # [cite: 121]
        
        # 6. 计算技术指标信号
        ta_signals = self._process_ta_signals(ta_codes, hist_df_all, spot_df) # [cite: 121]
        self._save_ta_signals_to_txt(ta_signals) # [cite: 121]

       
        # 7. 整理最终的 processed_data 字典
        processed_data = {
            'processed_main_report': processed_main_report, # [cite: 121]
            'processed_xstp_df': processed_xstp_df, # [cite: 122]
            'top_industry_cons_df': raw_data['top_industry_cons_df'], # [cite: 122]
            'spot_data_all': spot_df, # [cite: 122]
            **ta_signals, # [cite: 122]
            **raw_data # [cite: 122]
        }

 
        # 8. 生成最终 Excel 报告
        self.generate_final_excel(ta_signals, processed_data, raw_data) # [cite: 122]


if __name__ == '__main__':
    # 示例运行逻辑 (如果代码是作为独立脚本运行)
    analyzer = StockAnalyzer()
    analyzer.analyze_shares()
